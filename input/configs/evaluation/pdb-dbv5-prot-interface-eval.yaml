config_type: "evaluation" # options: data_preprocessor, prediction, evaluation

# Input Settings:
  ## initialize base input folder name
  ## provide path to dataset folder
input_settings:
  # Base input directory
  input_dir: "output/raw"

  file_names:
    # experiment_name (to be used as a key in comparative analysis): file_name
    "LR": "20230405/pdb-dbv5_lr_output.csv"
    "RF": "20230405/pdb-dbv5_rf_output.csv"
    "GCN2-FFN2": "20230416/gnn2_ff2_gcn_ff_output.csv"
    "GAT2-FFN2": "20230416/gnn2_ff2_gat_ff_output.csv"
    "GCN6-FFN2": "20230416/gnn6_ff2_gcn_ff_output.csv"
    "GAT6-FFN2": "20230416/gnn6_ff2_gat_ff_output.csv"

evaluation_settings:
  pos_label: 1
  neg_label: 0
  # metrics
  auroc: True
  auprc: True
  f1: True
  accuracy: True


output_settings:
  output_dir: "output"
  evaluation_dir: "evaluation"
  visualization_dir: "visualizations"
  dataset_dir: "20230419"
  prefix: "pdb-dbv5"# default: none; default file name = <output_prefix>_<model_name>_output.csv