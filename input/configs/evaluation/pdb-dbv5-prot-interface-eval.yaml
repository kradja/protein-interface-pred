config_type: "evaluation" # options: data_preprocessor, prediction, evaluation

# Input Settings:
  ## initialize base input folder name
  ## provide path to dataset folder
input_settings:
  # Base input directory
  input_dir: "output/raw"

  file_names:
    # experiment_name (to be used as a key in comparative analysis): file_name
    "LR": "20230405/pdb-dbv5_lr_output.csv"
    "RF": "20230405/pdb-dbv5_rf_output.csv"
    "GCN": "20230424/gnn2_ff2_pn0.1_gcn_ff_output.csv"
    "GAT": "20230424/gnn2_ff2_pn0.1_gat_ff_output.csv"
    "NNConv": "20230424/gnn2_ff2_pn0.1_nnconv_ff_output.csv"
    "EGAT": "20230424/gnn2_ff2_pn0.1_egat_ff_output.csv"
    "W-GCN": "20230426/gnn2_ff2_pn0.1_weightedloss_gcn_ff_output.csv"
    "W-GAT": "20230426/gnn2_ff2_pn0.1_weightedloss_gat_ff_output.csv"
    "W-NNConv": "20230424/gnn2_ff2_pn0.1_weightedloss_nnconv_ff_output.csv"
    "W-EGAT": "20230426/gnn2_ff2_pn0.1_weightedloss_egat_ff_output.csv"


evaluation_settings:
  pos_label: 1
  neg_label: 0
  # metrics
  auroc: True
  auprc: True
  f1: True
  accuracy: True


output_settings:
  output_dir: "output"
  evaluation_dir: "evaluation"
  visualization_dir: "visualizations"
  dataset_dir: "20230426"
  prefix: "pn0.1"# default: none; default file name = <output_prefix>_<model_name>_output.csv